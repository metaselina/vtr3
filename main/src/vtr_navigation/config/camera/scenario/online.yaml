/**:
  ros__parameters:
    ############ system configuration ############
    # Data logging
    log_to_file: true
    log_debug: false
    log_enabled:
      [
        "navigator",
        "map_projector",
        "tactic",
        "tactic.module",
        "mission_planning_server",
        "state_machine",
        "pose_graph",
        "stereo.pipeline",
        "path_tracker",
      ]

    # The sensor frame from the urdf (also defines the rig name)
    camera_frame: front_xb3
    # The control frame from the urdf
    robot_frame: base_link
    #
    lidar_topic: not_used

    ############ map projection configuration ############
    map_projection:
      origin_lat: 43.78220
      origin_lng: -79.4661
      origin_theta: 1.3 # positive == clockwise
      scale: 1.0

    ############ tactic configuration ############
    tactic:
      visualize: false
      extrapolate_odometry: true # path tracker
      localization_only_keyframe: true
      localization_skippable: false
      default_loc_cov: [1.0, 0.5, 0.5, 0.25, 0.25, 0.5]
      chain:
        min_cusp_distance: 1.5
        angle_weight: 7.0
        search_depth: 20
        search_back_depth: 10
        distance_warning: 3.0
      live_mem:
        enable: true
        lookahead_distance: 100
        window_size: 10
      map_mem:
        enable: true
        lookahead_distance: 15
        vertex_life_span: 10

      visualize: true
      vis_loc_path_offset: [0., 0., 0.]

    ############ pipeline configuration ############
    pipeline:
      type: stereo
      preprocessing: ["extraction", "triangulation"]
      odometry: ["recall", "matcher", "ransac", "steam", "vertex_test"]
      bundle_adjustment: ["recall", "steam"]
      localization:
        [
          "recall",
          "sub_map_extraction",
          "experience_triage",
          "migration",
          "matcher",
          "ransac",
          "steam",
        ]

    preprocessing:
      # conversion+extraction module
      extraction:
        type: conversion_extraction

        # Conversion-Extraction module
        # conversions: []
        # conversions: ["RGB_TO_GRAYSCALE"]
        conversions: ["RGB_TO_GRAYSCALE", "RGB_TO_COLOR_CONSTANT"]
        color_constant:
          weights: [0.43]

        extractor:
          type: ASRL_GPU_SURF # ASRL_GPU_SURF, OPENCV_ORB
          # channels: ["grayscale"]
          channels: ["grayscale", "cc_0.430000"]
          visualize_raw_features: false
          visualize_disparity: false
          use_learned: true

          # converter/extraction/extractor/patchSize: 64
          # ORB extraction module
          orb:
            num_detector_features: 10000
            num_binned_features: 2000
            fastThreshold: 5
            x_bins: 8
            y_bins: 6
            edgeThreshold: 16
            matcher:
              stereo_descriptor_match_thresh: 0.3
              stereo_y_tolerance: 2.0
              scale_x_tolerance_by_y: false

          # SURF extraction module
          surf:
            upright_flag: true
            threshold: .000001
            nOctaves: 4
            nIntervals: 4
            initialScale: 1.5
            edgeScale: 1.5
            l1: 2.0 # 3.f/1.5f
            l2: 3.333333 # 5.f/1.5f
            l3: 2.0 # 3.f/1.5f
            l4: 0.666667 # 1.f/1.5f
            initialStep: 1
            targetFeatures: 1000
            detector_threads_x: 16
            detector_threads_y: 16
            regions_horizontal: 16
            regions_vertical: 16
            regions_target: 1000
            stereoDisparityMinimum: 0.0
            stereoDisparityMaximum: 64.0
            stereoCorrelationThreshold: .79
            stereoYTolerance: 0.9
            stereoScaleTolerance: .9

          learned:
            # we're providing the surf settings (don't change this param, use a different file)
            type: "LEARNED_FEATURE"
            # modelPath: "/home/asrl/libtorch_example/data/feature_detector.pt"
            # modelPath: "/home/asrl/libtorch_example/data/feature_detector_16_crop_w16h15.pt"

            # modelPath: "/home/asrl/libtorch_example/data/feature_detector_snow_16_h16w16.pt"
            # modelPath: "/home/asrl/libtorch_example/data/feature_detector_snow_32_h16w16.pt"
            # modelPath: "/home/asrl/libtorch_example/data/feature_detector_dark_32_h15w16.pt"
            # modelPath: "/home/asrl/libtorch_example/data/feature_detector_dark_extend_32_h15w16.pt"
            
            # modelPath: "/home/asrl/libtorch_example/data/feature_detector_snow_354_32_h16w16.pt"
            # modelPath: "/home/asrl/libtorch_example/data/feature_detector_snow_391_16_h16w16.pt"
            # modelPath: "/home/asrl/libtorch_example/data/feature_detector_dark_extend_395_32_h16w16.pt"
            # modelPath: "/home/asrl/libtorch_example/data/feature_detector_dark_extend_479_32_h16w16.pt"
            modelPath: "/home/asrl/libtorch_example/data/feature_detector_dark_extend_585_16_h16w16.pt"
            # modelPath: "/home/asrl/libtorch_example/data/feature_detector_dark_165_32_h16w16.pt"
            # modelPath: "/home/asrl/libtorch_example/data/feature_detector_dark_62_16_h16w16.pt"


            stereoDisparityMinimum: 0.1
            stereoDisparityMaximum: 100.0
            # minDisparity: 0
            # numDisparities: 48
            # blockSize: 5
            # preFilterCap: 30
            # uniquenessRatio: 20
            # P1: 200
            # P2: 800
            # speckleWindowSize: 200
            # speckleRange: 1
            # disp12MaxDiff: -1
            # fullDP: false

      # triangulation module
      triangulation:
        visualize_features: false
        visualize_stereo_features: false

    odometry:
      recall:
        type: landmark_recall
        landmark_source: live

      matcher:
        check_response: true
        tight_matching_pixel_thresh: 20
        matching_pixel_thresh: 400
        tight_matching_x_sigma: 0.6
        tight_matching_y_sigma: 0.6
        tight_matching_theta_sigma: 0.6
        max_point_depth: 500.0
        descriptor_thresh: 0.1
        parallel_threads: 8
        prediction_method: se3
        visualize_feature_matches: false

      ransac:
        iterations: 2000
        threshold: 5.0
        early_stop_min_inliers: 200
        min_inliers: 15
        visualize_ransac_inliers: false

      steam: # Keyframe optimisation
        iterations: 5
        pose_prior_enable: false
        ang_vel_std_dev_z: 0.2
        verbose: false
        use_T_q_m_prior: false
        # solver_type: "LevenburgMarquardt"
        depth_prior_enable: false
        trajectory_smoothing: true
        lin_acc_std_dev_x: 10.0
        lin_acc_std_dev_y: 10.0
        lin_acc_std_dev_z: 10.0
        ang_acc_std_dev_x: 1.0
        ang_acc_std_dev_y: 1.0
        ang_acc_std_dev_z: 1.0
        velocity_prior: false
        lin_vel_mean_x: 4.0
        lin_vel_mean_y: 0.0
        lin_vel_mean_z: 0.0
        ang_vel_mean_x: 0.0
        ang_vel_mean_y: 0.0
        ang_vel_mean_z: 0.0
        lin_vel_std_dev_x: 8.0
        lin_vel_std_dev_y: 3.0
        lin_vel_std_dev_z: 0.5
        ang_vel_std_dev_x: 0.5
        ang_vel_std_dev_y: 0.5
        perform_planarity_check: false
        plane_distance: 20.0
        min_point_depth: 0.0
        max_point_depth: 200.0

      vertex_test:
        match_threshold_min_count: 50
        match_threshold_fail_count: 15 # todo: better results with 25 I think

    bundle_adjustment:
      recall:
        type: stereo_windowed_recall
        window_size: 5

      steam:
        trajectory_smoothing: true
        velocity_prior: false
        verbose: false
        use_T_q_m_prior: false
        # solver_type: "LevenburgMarquardt"
        depth_prior_enable: true
        depth_prior_weight: 1000000000.0
        max_point_depth: 800.0
        min_point_depth: 1.0
        perform_planarity_check: false
        plane_distance: 20.0

    localization:
      recall:
        type: landmark_recall
        landmark_source: live

      experience_triage:
        only_privileged: true

      migration:
        type: landmark_migration

      matcher:
        descriptor_thresh_cpu: 0.7 #0.115
        descriptor_thresh_gpu: 100.0 
        target_match_count: 200
        min_match_count: 20
        tight_matching_pixel_thresh: 50
        matching_pixel_thresh: 200
        min_response_ratio: 0.0
        time_allowance: 2000.0
        visualize_ransac_inliers: false
        min_track_length: 1
        max_depth_diff: 5.0
        max_landmark_depth: 200.0
        screen_matched_landmarks: true
        use_learned_features: true
        match_on_gpu: false
        match_gpu_knn_match_num: 8

      steam:
        iterations: 15
        pose_prior_enable: true
        verbose: false
        use_T_q_m_prior: true
        # solver_type: "LevenburgMarquardt"
        depth_prior_enable: false
        trajectory_smoothing: false
        velocity_prior: false
        save_trajectory: false
